{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSeekMoE architecture recreation attempt\n",
    "\n",
    "inpired by paper: https://arxiv.org/pdf/2401.06066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct computation attempt\n",
    "\n",
    "before we try to build a class in `nn.Module` lets try to grasp what computation we are trying o achive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 32])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "sequence_len = 10\n",
    "embedding_dim = 32\n",
    "num_experts = 14\n",
    "m = 2\n",
    "k = 3\n",
    "dim_experts = embedding_dim//m\n",
    "num_shared_exp = 3\n",
    "\n",
    "# assume outputs from selfattention layer\n",
    "attention_output = torch.rand([batch_size,\n",
    "                               sequence_len,\n",
    "                               embedding_dim], dtype=torch.float32)\n",
    "\n",
    "attention_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 28])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = torch.rand([dim_experts,\n",
    "                        num_experts*m], dtype=torch.float32)\n",
    "\n",
    "scores = F.softmax(torch.einsum(\"btd,wn->btn\", attention_output, centroids), dim=-1)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get topk elements\n",
    "\n",
    "topk_values, topk_indices = torch.topk(scores, k=m*k, dim=-1)\n",
    "\n",
    "mask = torch.zeros_like(scores).scatter_(-1, topk_indices, 1.0)\n",
    "\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 3, 32])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_experts = torch.rand([num_shared_exp,\n",
    "                             dim_experts,\n",
    "                             embedding_dim], dtype=torch.float32)\n",
    "\n",
    "shared_out = torch.einsum(\"btd,nwd->btnd\", attention_output, shared_experts)\n",
    "shared_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 28, 32])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute expert weight multiplication\n",
    "\n",
    "experts_weights = torch.rand([m*num_experts,\n",
    "                            dim_experts,\n",
    "                            embedding_dim], dtype=torch.float32)\n",
    "\n",
    "no_filter_experts_out = torch.einsum(\"btd,nwd->btnd\", attention_output, experts_weights)\n",
    "\n",
    "no_filter_experts_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 28, 32])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter\n",
    "experts_out = mask.unsqueeze(-1) * no_filter_experts_out\n",
    "experts_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 31, 32])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_experts_out = torch.cat((shared_out, experts_out), dim=2)\n",
    "total_experts_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 32])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed = total_experts_out.sum(dim=2)\n",
    "compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 32])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = attention_output + compressed\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Moe(nn.Module):\n",
    "    def __init__(self, num_experts, num_shared, k, expert_dim, num_tokens, embedding_dim):\n",
    "        super(Moe, self).__init__()\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "        self.centroids = torch.rand([embedding_dim,\n",
    "                                     num_experts], dtype=torch.float32)\n",
    "        \n",
    "        self.shared_experts = torch.rand([num_shared,\n",
    "                                     expert_dim,\n",
    "                                     embedding_dim], dtype=torch.float32)\n",
    "        \n",
    "        self.expert_weights = torch.rand([num_experts,\n",
    "                                     expert_dim,\n",
    "                                     embedding_dim], dtype=torch.float32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # assume x is the output of a attention layer\n",
    "        scores = F.softmax(torch.einsum(\"btd,dn->btn\", x, self.centroids), dim=-1)\n",
    "\n",
    "        topk_values, topk_indices = torch.topk(scores, k=self.k, dim=-1)\n",
    "        \n",
    "        mask = torch.zeros_like(scores).scatter_(-1, topk_indices, 1.0)\n",
    "\n",
    "        shared_out = torch.einsum(\"btd,nwd->btnd\", x, self.shared_experts)\n",
    "\n",
    "        experts_out = torch.einsum(\"btd,nwd->btnd\", x, self.expert_weights)\n",
    "\n",
    "        routed_experts = mask.unsqueeze(-1) * experts_out\n",
    "\n",
    "        total_experts_out = torch.cat((shared_out, routed_experts), dim=2)\n",
    "\n",
    "        return total_experts_out.sum(dim=2), (scores, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 32])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moe = Moe(14, 6, 3, 16, 10, 32)\n",
    "\n",
    "moe(torch.rand([8, 10, 32], dtype=torch.float32))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert Load Balancing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.6667,  0.0000, 42.0000,  0.0000,  4.6667, 14.0000,  9.3333,  0.0000,\n",
       "        14.0000, 32.6667,  0.0000,  0.0000,  0.0000, 18.6667])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# direct computation attempt\n",
    "mask = moe(torch.rand([8, 10, 32], dtype=torch.float32))[1][1]\n",
    "\n",
    "# calculating fi\n",
    "sum_vec = mask.sum(1)\n",
    "fi = (num_experts / k) * sum_vec\n",
    "fi[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0441, 0.0244, 0.1539, 0.0340, 0.0643, 0.0730, 0.1039, 0.0457, 0.1177,\n",
       "        0.1361, 0.0364, 0.0259, 0.0335, 0.1069])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating pi\n",
    "scores = moe(torch.rand([8, 10, 32], dtype=torch.float32))[1][0]\n",
    "\n",
    "sum_vec = scores.sum(1)\n",
    "pi = sum_vec / sequence_len\n",
    "pi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2619)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.03\n",
    "\n",
    "exp_bal_loss = alpha * (pi * fi).sum()\n",
    "\n",
    "exp_bal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in future notebooks we'll create a full loss function for a deepseek architecture language model\n",
    "\n",
    "### for now, this is all we need to know about deepseek moe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
